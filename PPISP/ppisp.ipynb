{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b071d833",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-16T04:56:25.112814Z",
     "iopub.status.busy": "2024-12-16T04:56:25.111980Z",
     "iopub.status.idle": "2024-12-16T04:56:25.754803Z",
     "shell.execute_reply": "2024-12-16T04:56:25.753985Z"
    },
    "papermill": {
     "duration": 0.649104,
     "end_time": "2024-12-16T04:56:25.756646",
     "exception": false,
     "start_time": "2024-12-16T04:56:25.107542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/ppispd/train_2140.pkl\n",
      "/kaggle/input/ppispd/test_2140.pkl\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "827fb417",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T04:56:25.763475Z",
     "iopub.status.busy": "2024-12-16T04:56:25.762865Z",
     "iopub.status.idle": "2024-12-16T04:56:28.751826Z",
     "shell.execute_reply": "2024-12-16T04:56:28.750842Z"
    },
    "papermill": {
     "duration": 2.994173,
     "end_time": "2024-12-16T04:56:28.753648",
     "exception": false,
     "start_time": "2024-12-16T04:56:25.759475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed = 2024\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5ad688e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T04:56:28.760683Z",
     "iopub.status.busy": "2024-12-16T04:56:28.759918Z",
     "iopub.status.idle": "2024-12-16T04:56:28.765466Z",
     "shell.execute_reply": "2024-12-16T04:56:28.764733Z"
    },
    "papermill": {
     "duration": 0.010558,
     "end_time": "2024-12-16T04:56:28.766949",
     "exception": false,
     "start_time": "2024-12-16T04:56:28.756391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PPIDataset(Dataset):\n",
    "    def __init__(self, protein_pairs):\n",
    "        self.protein_pairs = protein_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.protein_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.protein_pairs[idx]\n",
    "        pair['label'][:, 2] = (pair['label'][:, 2] == 1)\n",
    "        return {\n",
    "            'l_features': torch.FloatTensor(pair['l_bert_features']),\n",
    "            'r_features': torch.FloatTensor(pair['r_bert_features']),\n",
    "            'labels': torch.LongTensor(pair['label'])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9c338dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T04:56:28.773238Z",
     "iopub.status.busy": "2024-12-16T04:56:28.772952Z",
     "iopub.status.idle": "2024-12-16T04:56:28.783953Z",
     "shell.execute_reply": "2024-12-16T04:56:28.783164Z"
    },
    "papermill": {
     "duration": 0.016068,
     "end_time": "2024-12-16T04:56:28.785552",
     "exception": false,
     "start_time": "2024-12-16T04:56:28.769484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PPIPredictor(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim=1024,\n",
    "                 hidden_dim=512,\n",
    "                 num_heads=8,\n",
    "                 num_layers=2,\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Dimensionality reduction for BERT features\n",
    "        self.l_feature_projection = nn.Linear(input_dim, hidden_dim)\n",
    "        self.r_feature_projection = nn.Linear(input_dim, hidden_dim)\n",
    "        self.l_ln = nn.LayerNorm(hidden_dim)\n",
    "        self.r_ln = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        # Cross-attention layers using MultiheadAttention\n",
    "        self.l2r_attention_layers = nn.ModuleList([\n",
    "            nn.MultiheadAttention(hidden_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.r2l_attention_layers = nn.ModuleList([\n",
    "            nn.MultiheadAttention(hidden_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Layer normalization for cross-attention outputs\n",
    "        self.l2r_norm_layers = nn.ModuleList([\n",
    "            nn.LayerNorm(hidden_dim) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.r2l_norm_layers = nn.ModuleList([\n",
    "            nn.LayerNorm(hidden_dim) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Final prediction layers\n",
    "        self.interaction_predictor = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.LayerNorm(hidden_dim),  # Added normalization here\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),  # New linear layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.LayerNorm(hidden_dim // 2),  # Normalization after new layer\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, l_features, r_features):\n",
    "        batch_size = l_features.size(0)\n",
    "\n",
    "        # Project features to lower dimension\n",
    "        l_hidden = self.l_ln(self.dropout(F.relu(self.l_feature_projection(l_features))))\n",
    "        r_hidden = self.r_ln(self.dropout(F.relu(self.r_feature_projection(r_features))))\n",
    "\n",
    "        # Apply cross-attention layers\n",
    "        for l2r_attn, r2l_attn, l2r_norm, r2l_norm in zip(self.l2r_attention_layers, \n",
    "                                                         self.r2l_attention_layers,\n",
    "                                                         self.l2r_norm_layers, \n",
    "                                                         self.r2l_norm_layers):\n",
    "            # Ligand attending to receptor\n",
    "            l2r_output, _ = l2r_attn(l_hidden, r_hidden, r_hidden)\n",
    "            l_hidden = l2r_norm(l_hidden + self.dropout(l2r_output))  # Residual + normalization\n",
    "\n",
    "            # Receptor attending to ligand\n",
    "            r2l_output, _ = r2l_attn(r_hidden, l_hidden, l_hidden)\n",
    "            r_hidden = r2l_norm(r_hidden + self.dropout(r2l_output))  # Residual + normalization\n",
    "\n",
    "        # Create all pairs of residue representations\n",
    "        l_hidden_expanded = l_hidden.unsqueeze(2).expand(-1, -1, r_hidden.size(1), -1)\n",
    "        r_hidden_expanded = r_hidden.unsqueeze(1).expand(-1, l_hidden.size(1), -1, -1)\n",
    "\n",
    "        # Concatenate ligand and receptor representations for each pair\n",
    "        pair_repr = torch.cat([l_hidden_expanded, r_hidden_expanded], dim=-1)\n",
    "\n",
    "        # Predict interaction scores\n",
    "        interaction_scores = self.interaction_predictor(pair_repr).squeeze(-1)\n",
    "\n",
    "        return interaction_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b7f02b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T04:56:28.793281Z",
     "iopub.status.busy": "2024-12-16T04:56:28.792672Z",
     "iopub.status.idle": "2024-12-16T04:56:28.796910Z",
     "shell.execute_reply": "2024-12-16T04:56:28.796283Z"
    },
    "papermill": {
     "duration": 0.009216,
     "end_time": "2024-12-16T04:56:28.798502",
     "exception": false,
     "start_time": "2024-12-16T04:56:28.789286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WeightedBCELoss(nn.Module):\n",
    "    def __init__(self, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(\n",
    "            pred,\n",
    "            target,\n",
    "            pos_weight=self.pos_weight\n",
    "        )\n",
    "        return bce_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "626080da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T04:56:28.805901Z",
     "iopub.status.busy": "2024-12-16T04:56:28.805685Z",
     "iopub.status.idle": "2024-12-16T04:56:28.811879Z",
     "shell.execute_reply": "2024-12-16T04:56:28.811070Z"
    },
    "papermill": {
     "duration": 0.012376,
     "end_time": "2024-12-16T04:56:28.813552",
     "exception": false,
     "start_time": "2024-12-16T04:56:28.801176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, criterion, device, gradient_clip_val=1.0):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        l_features = batch['l_features'].to(device)\n",
    "        r_features = batch['r_features'].to(device)\n",
    "        labels = batch['labels']\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        pred = model(l_features, r_features)\n",
    "\n",
    "        # Compute loss for ground-truth interactions\n",
    "        interaction_targets = []\n",
    "        interaction_preds = []\n",
    "        for label_tensor in labels[0]:\n",
    "            l_idx, r_idx, target = label_tensor\n",
    "            interaction_targets.append(target.float().to(device))\n",
    "            interaction_preds.append(pred[0, l_idx, r_idx])\n",
    "\n",
    "        interaction_targets = torch.stack(interaction_targets).to(device)\n",
    "        interaction_preds = torch.stack(interaction_preds).to(device)\n",
    "        loss = criterion(interaction_preds, interaction_targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip_val)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18077328",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T04:56:28.819896Z",
     "iopub.status.busy": "2024-12-16T04:56:28.819461Z",
     "iopub.status.idle": "2024-12-16T04:56:28.823397Z",
     "shell.execute_reply": "2024-12-16T04:56:28.822688Z"
    },
    "papermill": {
     "duration": 0.008771,
     "end_time": "2024-12-16T04:56:28.824890",
     "exception": false,
     "start_time": "2024-12-16T04:56:28.816119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight is not None and m.weight.dim() >= 2:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "    if hasattr(m, 'bias') and m.bias is not None:\n",
    "        nn.init.constant_(m.bias, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eca8b4e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T04:56:28.831061Z",
     "iopub.status.busy": "2024-12-16T04:56:28.830847Z",
     "iopub.status.idle": "2024-12-16T04:56:28.837416Z",
     "shell.execute_reply": "2024-12-16T04:56:28.836700Z"
    },
    "papermill": {
     "duration": 0.011469,
     "end_time": "2024-12-16T04:56:28.839023",
     "exception": false,
     "start_time": "2024-12-16T04:56:28.827554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "def train(config, protein_pairs):\n",
    "    # Seed setup for reproducibility\n",
    "    seed = 2024\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    train_dataset = PPIDataset(protein_pairs)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "\n",
    "    model = PPIPredictor(input_dim=1024, hidden_dim=config['hidden_dim'],\n",
    "                         num_heads=config['num_heads'], num_layers=config['num_layers'],\n",
    "                         dropout=config['dropout']).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "    criterion = WeightedBCELoss(pos_weight=torch.tensor(config['pos_weight'], dtype=torch.float).to(device))\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=config['epochs'], eta_min=config['eta_min'])\n",
    "\n",
    "\n",
    "    # Initialize model weights\n",
    "    model.apply(init_weights)\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, criterion, device,\n",
    "                                 gradient_clip_val=config['gradient_clip_val'])\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{config['epochs']}, Loss: {train_loss:.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0a85a89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T04:56:28.845285Z",
     "iopub.status.busy": "2024-12-16T04:56:28.845041Z",
     "iopub.status.idle": "2024-12-16T04:56:29.843121Z",
     "shell.execute_reply": "2024-12-16T04:56:29.842427Z"
    },
    "papermill": {
     "duration": 1.003328,
     "end_time": "2024-12-16T04:56:29.845099",
     "exception": false,
     "start_time": "2024-12-16T04:56:28.841771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def eval(model, protein_pairs, device='cuda'):\n",
    "    test_dataset = PPIDataset(protein_pairs)\n",
    "    dataloader = DataLoader(test_dataset, batch_size=1)\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            l_features = batch['l_features'].to(device)\n",
    "            r_features = batch['r_features'].to(device)\n",
    "            labels = batch['labels']\n",
    "\n",
    "            pred = model(l_features, r_features)\n",
    "\n",
    "            for label_tensor in labels[0]:\n",
    "                l_idx, r_idx, target = label_tensor\n",
    "                all_labels.append(target.item())\n",
    "                all_preds.append(torch.sigmoid(pred[0, l_idx, r_idx]).item())\n",
    "\n",
    "    # Convert lists to NumPy arrays for metric calculations\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "\n",
    "    # Metrics calculation\n",
    "    binary_preds = (all_preds >= 0.5).astype(int)\n",
    "    accuracy = metrics.accuracy_score(all_labels, binary_preds)\n",
    "    precision = metrics.precision_score(all_labels, binary_preds)\n",
    "    recall = metrics.recall_score(all_labels, binary_preds)\n",
    "    f1 = metrics.f1_score(all_labels, binary_preds)\n",
    "    pr_auc = metrics.average_precision_score(all_labels, all_preds)\n",
    "    roc_auc = metrics.roc_auc_score(all_labels, all_preds)\n",
    "\n",
    "    return accuracy, precision, recall, f1, pr_auc, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "079fbf7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T04:56:29.852267Z",
     "iopub.status.busy": "2024-12-16T04:56:29.851850Z",
     "iopub.status.idle": "2024-12-16T04:56:29.856051Z",
     "shell.execute_reply": "2024-12-16T04:56:29.855411Z"
    },
    "papermill": {
     "duration": 0.009293,
     "end_time": "2024-12-16T04:56:29.857602",
     "exception": false,
     "start_time": "2024-12-16T04:56:29.848309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size': 1,  \n",
    "    'hidden_dim': 768,  \n",
    "    'num_heads': 16,\n",
    "    'num_layers': 2,\n",
    "    'dropout': 0.2,  \n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 1e-5,\n",
    "    'eta_min': 1e-6,\n",
    "    'epochs': 58,\n",
    "    'pos_weight': 10.0,  \n",
    "    'gradient_clip_val': 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1c9c25b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T04:56:29.864500Z",
     "iopub.status.busy": "2024-12-16T04:56:29.863799Z",
     "iopub.status.idle": "2024-12-16T04:57:04.297148Z",
     "shell.execute_reply": "2024-12-16T04:57:04.296182Z"
    },
    "papermill": {
     "duration": 34.438988,
     "end_time": "2024-12-16T04:57:04.299303",
     "exception": false,
     "start_time": "2024-12-16T04:56:29.860315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"/kaggle/input/ppispd/train_2140.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "train_protein_pairs = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8eb0c70b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T04:57:04.306625Z",
     "iopub.status.busy": "2024-12-16T04:57:04.306331Z",
     "iopub.status.idle": "2024-12-16T04:57:14.313703Z",
     "shell.execute_reply": "2024-12-16T04:57:14.312964Z"
    },
    "papermill": {
     "duration": 10.013055,
     "end_time": "2024-12-16T04:57:14.315601",
     "exception": false,
     "start_time": "2024-12-16T04:57:04.302546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"/kaggle/input/ppispd/test_2140.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "test_protein_pairs = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c7e2ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T04:57:14.322764Z",
     "iopub.status.busy": "2024-12-16T04:57:14.322470Z",
     "iopub.status.idle": "2024-12-16T16:43:44.204201Z",
     "shell.execute_reply": "2024-12-16T16:43:44.203302Z"
    },
    "papermill": {
     "duration": 42389.89412,
     "end_time": "2024-12-16T16:43:44.212914",
     "exception": false,
     "start_time": "2024-12-16T04:57:14.318794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/58, Loss: 1.1789\n",
      "Epoch 2/58, Loss: 1.0934\n",
      "Epoch 3/58, Loss: 1.0496\n",
      "Epoch 4/58, Loss: 0.9980\n",
      "Epoch 5/58, Loss: 0.9419\n",
      "Epoch 6/58, Loss: 0.8734\n",
      "Epoch 7/58, Loss: 0.8095\n",
      "Epoch 8/58, Loss: 0.7502\n",
      "Epoch 9/58, Loss: 0.7017\n",
      "Epoch 10/58, Loss: 0.6579\n",
      "Epoch 11/58, Loss: 0.6191\n",
      "Epoch 12/58, Loss: 0.5875\n",
      "Epoch 13/58, Loss: 0.5563\n",
      "Epoch 14/58, Loss: 0.5301\n",
      "Epoch 15/58, Loss: 0.5076\n",
      "Epoch 16/58, Loss: 0.4876\n",
      "Epoch 17/58, Loss: 0.4668\n",
      "Epoch 18/58, Loss: 0.4519\n",
      "Epoch 19/58, Loss: 0.4337\n",
      "Epoch 20/58, Loss: 0.4173\n",
      "Epoch 21/58, Loss: 0.4042\n",
      "Epoch 22/58, Loss: 0.3909\n",
      "Epoch 23/58, Loss: 0.3790\n",
      "Epoch 24/58, Loss: 0.3657\n",
      "Epoch 25/58, Loss: 0.3549\n",
      "Epoch 26/58, Loss: 0.3457\n",
      "Epoch 27/58, Loss: 0.3352\n",
      "Epoch 28/58, Loss: 0.3250\n",
      "Epoch 29/58, Loss: 0.3167\n",
      "Epoch 30/58, Loss: 0.3078\n",
      "Epoch 31/58, Loss: 0.3003\n",
      "Epoch 32/58, Loss: 0.2926\n",
      "Epoch 33/58, Loss: 0.2846\n",
      "Epoch 34/58, Loss: 0.2775\n",
      "Epoch 35/58, Loss: 0.2704\n",
      "Epoch 36/58, Loss: 0.2642\n",
      "Epoch 37/58, Loss: 0.2566\n",
      "Epoch 38/58, Loss: 0.2517\n",
      "Epoch 39/58, Loss: 0.2474\n",
      "Epoch 40/58, Loss: 0.2417\n",
      "Epoch 41/58, Loss: 0.2360\n",
      "Epoch 42/58, Loss: 0.2320\n",
      "Epoch 43/58, Loss: 0.2278\n",
      "Epoch 44/58, Loss: 0.2241\n",
      "Epoch 45/58, Loss: 0.2194\n",
      "Epoch 46/58, Loss: 0.2178\n",
      "Epoch 47/58, Loss: 0.2139\n",
      "Epoch 48/58, Loss: 0.2109\n",
      "Epoch 49/58, Loss: 0.2086\n",
      "Epoch 50/58, Loss: 0.2067\n",
      "Epoch 51/58, Loss: 0.2044\n",
      "Epoch 52/58, Loss: 0.2035\n",
      "Epoch 53/58, Loss: 0.2022\n",
      "Epoch 54/58, Loss: 0.2009\n",
      "Epoch 55/58, Loss: 0.1999\n",
      "Epoch 56/58, Loss: 0.1993\n",
      "Epoch 57/58, Loss: 0.1982\n",
      "Epoch 58/58, Loss: 0.1988\n"
     ]
    }
   ],
   "source": [
    "model = train(config,train_protein_pairs)\n",
    "torch.save(model, \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fbe1baa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T16:43:44.226315Z",
     "iopub.status.busy": "2024-12-16T16:43:44.225854Z",
     "iopub.status.idle": "2024-12-16T16:44:48.835011Z",
     "shell.execute_reply": "2024-12-16T16:44:48.834067Z"
    },
    "papermill": {
     "duration": 64.623535,
     "end_time": "2024-12-16T16:44:48.842517",
     "exception": false,
     "start_time": "2024-12-16T16:43:44.218982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8583, Precision: 0.2292, Recall: 0.2363, F1 Score: 0.2327\n",
      "PR AUC: 0.1998, ROC AUC: 0.6967\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1, pr_auc, roc_auc = eval(model, test_protein_pairs)\n",
    "print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "print(f\"PR AUC: {pr_auc:.4f}, ROC AUC: {roc_auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6271605,
     "sourceId": 10157478,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 42507.983071,
   "end_time": "2024-12-16T16:44:50.771578",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-16T04:56:22.788507",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
